<img src="./fig1.png" width="450px"/>

<img src="./fig2.png" width="450px"/>

## Improving Transformers World Model - Pytorch (wip)

Implementation of the new SOTA for model based RL, from the paper [Improving Transformer World Models for Data-Efficient RL](https://arxiv.org/abs/2502.01591), in Pytorch.

They significantly outperformed DreamerV3 with a transformer world model and a less complicated setup, on Craftax (simplified Minecraft environment).

## Citations

```bibtex
@inproceedings{Dedieu2025ImprovingTW,
    title   = {Improving Transformer World Models for Data-Efficient RL},
    author  = {Antoine Dedieu and Joseph Ortiz and Xinghua Lou and Carter Wendelken and Wolfgang Lehrach and J. Swaroop Guntupalli and Miguel L{\'a}zaro-Gredilla and Kevin Patrick Murphy},
    year    = {2025},
    url     = {https://api.semanticscholar.org/CorpusID:276107865}
}
```
